{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use hive instead of mysql as data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from pyspark.sql import Row\n",
    "import scipy\n",
    "\n",
    "import cv2\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## global parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# over write hive tables\n",
    "overwrite = True\n",
    "overwrite = False\n",
    "\n",
    "fg = 'cars'\n",
    "bg = 'none'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load image from hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "if 'aibgraz' in sqlContext.sql('show databases').rdd.map(lambda r : r.result).collect():\n",
    "    sqlContext.sql('use aibgraz')\n",
    "    if 'graz02' in sqlContext.sql('show tables').rdd.map(lambda r : r.tableName).collect():\n",
    "        \n",
    "\n",
    "        print('success!')\n",
    "    else:\n",
    "        print ('table aibgraz.graz02 is not exists, please create it firstly')\n",
    "else:\n",
    "    print('database aibgraz is not exists, please create it firstly')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# throw away detected features whose frame size is less than min_sigma\n",
    "feat_min_sigma=2.5\n",
    "#\n",
    "feat_rescale=6 \n",
    "#  \n",
    "feat_desc_property = 0.01\n",
    "\n",
    "#feat_max_num=\n",
    "# name of feature table\n",
    "szFeatureTable = 'graz02_feature'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def block_feat(row):\n",
    "    img = cv2.imread(row.path, cv2.IMREAD_GRAYSCALE)\n",
    "    M,N = img.shape\n",
    "    featureDetector = cv2.xfeatures2d.SIFT_create()\n",
    "    #featureDetector = cv2.xfeatures2d.SIFT_create()\n",
    "    describeExtractor = featureDetector\n",
    "        \n",
    "    #detector\n",
    "    kp = featureDetector.detect(img, None)\n",
    "    print(len(kp))\n",
    "    #print(kp[0])\n",
    "    \n",
    "    #frame selection\n",
    "    kp_sel = []\n",
    "    for p in kp:\n",
    "        scale = p.size;\n",
    "        # \n",
    "        if scale <= feat_min_sigma:\n",
    "            continue\n",
    "        x= p.pt[0]\n",
    "        y= p.pt[1]\n",
    "        R=scale*feat_rescale\n",
    "        keep = x - R >= 0  and\\\n",
    "               x + R < N   and\\\n",
    "               y - R >= 0  and\\\n",
    "               y + R < M;\n",
    "        if (keep==True):\n",
    "            kp_sel.append(p)\n",
    "\n",
    "    #print(len(kp_sel))\n",
    "    nDesc = len(kp_sel)\n",
    "    nDesc_sel = int(nDesc*feat_desc_property)\n",
    "    if (nDesc_sel <= 1):\n",
    "        nDesc_sel = 1\n",
    "        \n",
    "        \n",
    "    print(nDesc)\n",
    "    print(nDesc_sel)\n",
    "    \n",
    "    usedMask = np.ndarray(nDesc, np.bool)\n",
    "    print(usedMask.shape)\n",
    "    usedMask[:]=False\n",
    "    usedMask[0:nDesc_sel]=True\n",
    "    for i in range(0, nDesc+1):\n",
    "        i1 = rand.randint(0, nDesc)\n",
    "        i2 = rand.randint(0, nDesc)\n",
    "        buf = usedMask[i1]\n",
    "        usedMask[i1]=usedMask[i2]\n",
    "        usedMask[i2]=buf\n",
    "    \n",
    "    kp_sel_2 = []\n",
    "    for i in range(nDesc):\n",
    "        if usedMask[i] == True:\n",
    "            kp_sel_2.append(kp_sel[i])\n",
    "            \n",
    "            \n",
    "    print(len(kp_sel_2))\n",
    "    \n",
    "    \n",
    "    #descriptor\n",
    "    _kp, des = describeExtractor.compute(img, kp_sel_2)\n",
    "        \n",
    "        \n",
    "    return Row(ind=row.ind,feat=des.tolist())\n",
    "\n",
    "#f=block_feat(df_graz02.rdd.first())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graz02_feature is exists\n"
     ]
    }
   ],
   "source": [
    "if overwrite == True:\n",
    "    print('overwrite mode. Drop table firstly!')\n",
    "    sqlContext.sql('drop table IF EXISTS %s'%(szFeatureTable))\n",
    "\n",
    "    \n",
    "# check whether feature table is exists.    \n",
    "if szFeatureTable in sqlContext.sql('show tables').rdd.map(lambda r : r.tableName).collect():\n",
    "    print('%s is exists'%(szFeatureTable))\n",
    "    #df_feat=sqlContext.sql('SELECT * FROM %s'%(szFeatureTable))\n",
    "else:\n",
    "    df_graz02=sqlContext.sql('SELECT * from graz02')\n",
    "    \n",
    "    \n",
    "    rdd_feat = df_graz02.rdd.map(block_feat)\n",
    "    df_feat = sqlContext.createDataFrame(rdd_feat)\n",
    "    df_feat.write.saveAsTable(name=szFeatureTable)\n",
    "    print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sqlContext.sql('show table extended like graz02_feature').show()\n",
    "#sqlContext.sql('select count(*) from graz02_feature').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df_train_feat(szCate):\n",
    "    return sqlContext.sql('SELECT graz02_feature.feat \\\n",
    "                                  FROM graz02 JOIN graz02_feature\\\n",
    "                                  ON (graz02.ind==graz02_feature.ind)\\\n",
    "                                  WHERE graz02.category = \"%s\" \\\n",
    "                                  AND graz02.cat_ind<=150'%(szCate))\n",
    "\n",
    "def create_df_test_feat(szCate):\n",
    "    return sqlContext.sql('SELECT graz02_feature.feat \\\n",
    "                                  FROM graz02 JOIN graz02_feature\\\n",
    "                                  ON (graz02.ind==graz02_feature.ind)\\\n",
    "                                  WHERE (graz02.category = \"%s\" \\\n",
    "                                        AND graz02.cat_ind>150\\\n",
    "                                        AND graz02.cat_ind<=200)'%(szCate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train dectionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the maximum number of features to sample for training\n",
    "dict_max_nfeat = 1000\n",
    "dict_km_nwords = 200\n",
    "\n",
    "szCateInfoTable='graz02_cate_info'\n",
    "\n",
    "szDictionaryTable='dictionary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def block_dictionary(rdd_feat):\n",
    "    def _collect_features(rdd_np_feat):\n",
    "        # feature number of every image\n",
    "        nfeats = np.array(rdd_np_feat.map(lambda feat: feat.shape[0]).collect(), np.int32)\n",
    "        # total number of features in rdd_np_feat\n",
    "        av_nfeats = nfeats.sum()\n",
    "    \n",
    "        list_np_feat = rdd_np_feat.collect()\n",
    "    \n",
    "        descr = list_np_feat[0]\n",
    "\n",
    "        for i in range(1, len(list_np_feat)):\n",
    "            descr=np.concatenate((descr, list_np_feat[i]), axis=0)\n",
    "        \n",
    "        return descr\n",
    "\n",
    "    def _learn(descr):\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS,10, 1.0)\n",
    "        flags=cv2.KMEANS_RANDOM_CENTERS\n",
    "        comp,labels,centers = cv2.kmeans(descr, dict_km_nwords, None, criteria, 10, flags)\n",
    "        return centers\n",
    "\n",
    "\n",
    "    rdd_np_feat_ =  rdd_feat.map(lambda r: np.array(r.feat, np.float32))\n",
    "    \n",
    "    \n",
    "    descr_ = _collect_features(rdd_np_feat_)\n",
    "    dict_  = _learn(descr_)\n",
    "    \n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cate_dict(row):\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "#df_cate_info = sqlContext.sql('select category from %s'%(szCateInfoTable))\n",
    "#rdd_cate_info.show()\n",
    "#cate_dict(df_cate_info.rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458\n",
      "(1458, 128)\n",
      "863\n",
      "(863, 128)\n",
      "942\n",
      "(942, 128)\n",
      "928\n",
      "(928, 128)\n"
     ]
    }
   ],
   "source": [
    "if overwrite == True:\n",
    "    print('overwrite mode. Drop table firstly!')\n",
    "    sqlContext.sql('drop table IF EXISTS %s'%(szDictionaryTable))\n",
    "\n",
    "    \n",
    "# check whether feature table is exists.    \n",
    "if szDictionaryTable in sqlContext.sql('show tables').rdd.map(lambda r : r.tableName).collect():\n",
    "    print('%s is exists'%(szDictionaryTable))\n",
    "else:\n",
    "    df_cate_info = sqlContext.sql('select category from %s'%(szCateInfoTable))\n",
    "    dict_ = {}\n",
    "    list_cate = df_cate_info.rdd.collect()\n",
    "    for row in list_cate:\n",
    "        df_train_feat=create_df_train_feat(row.category)\n",
    "        descr_ = block_dictionary(df_train_feat.rdd)\n",
    "        dict_[row.category] = Row(category=row.category, dictionary=dict_.tolist())\n",
    "    \n",
    "    rdd_cate_dictionary = sc.parallelize(list_cate).map(lambda row : dict_[row.category])\n",
    "        \n",
    "    df_cate_dictionary=sqlContext.createDataFrame(rdd_cate_dictionary)\n",
    "    df_cate_dictionary.write.saveAsTable(name=szDictionaryTable)\n",
    "    #print(type(rdd_cate_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogram/ bag of words\n",
    "$\\mathbf{A}=$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "# \n",
    "hist_split=30\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block_hist(row):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
